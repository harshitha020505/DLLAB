{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPJT3YwDYUpbMl7dgGDFzC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha020505/DLLAB/blob/main/DL_LAB_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVsHQsLxiSiS"
      },
      "outputs": [],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 .Sample Code: Build a Simple Neural Network with PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Dummy dataset\n",
        "x = torch.randn(100, 3)\n",
        "y = torch.randn(100, 1)\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = SimpleNet()\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.01\n",
        ")\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Final loss:\", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01z0D9caPpcQ",
        "outputId": "2ba990f1-a86a-4a4a-977e-87f4478cb0d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 1.096414566040039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Sample Code: Simple Neural Network with TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Dummy data\n",
        "x = tf.random.normal((100, 3))\n",
        "y = tf.random.normal((100, 1))\n",
        "\n",
        "# Define model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1,\n",
        "                          input_shape=(3,))\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse')\n",
        "\n",
        "# Train model\n",
        "model.fit(x, y,\n",
        "          epochs=100,\n",
        "          verbose=0)\n",
        "print(\"Final loss:\",\n",
        "      model.evaluate(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EER9cotxRQbU",
        "outputId": "f4fbf877-faec-4f14-8e00-9739f4913742"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3492\n",
            "Final loss: 1.4951887130737305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKeH5K5fR5gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step function for binary classification\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights            # Stores weights\n",
        "        self.bias = bias                  # Stores bias\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        total = np.dot(self.weights, inputs) + self.bias  # Weighted sum\n",
        "        return step(total)                # Binary output\n",
        "\n",
        "# AND gate parameters\n",
        "weights = np.array([1,1,1])               # Both inputs must be 1\n",
        "bias = -2.5                              # Threshold shift\n",
        "\n",
        "and_gate = Perceptron(weights, bias)\n",
        "\n",
        "# Testing AND gate\n",
        "print(\"AND Gate\")\n",
        "for x in [(0,0,0), (0,0,1), (1,1,0), (1,1,1)]:\n",
        "    print(x, \"->\", and_gate.predict(np.array(x)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVcROX7v5UPr",
        "outputId": "20413e4d-929d-48c0-ea14-98f570ee3ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate\n",
            "(0, 0, 0) -> 0\n",
            "(0, 0, 1) -> 0\n",
            "(1, 1, 0) -> 0\n",
            "(1, 1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OR gate parameters\n",
        "weights = np.array([1, 1,1])               # Any one input activates output\n",
        "bias = -0.5                              # Lower threshold\n",
        "\n",
        "or_gate = Perceptron(weights, bias)\n",
        "\n",
        "# Testing OR gate\n",
        "print(\"\\nOR Gate\")\n",
        "for x in [(0,0,0), (0,1,1), (1,0,1), (1,1,1)]:\n",
        "    print(x, \"->\", or_gate.predict(np.array(x)))"
      ],
      "metadata": {
        "id": "-ffCq6S46gPD",
        "outputId": "b92932fe-4ead-4cb0-f6a9-90e16aea418b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OR Gate\n",
            "(0, 0, 0) -> 0\n",
            "(0, 1, 1) -> 1\n",
            "(1, 0, 1) -> 1\n",
            "(1, 1, 1) -> 1\n"
          ]
        }
      ]
    }
  ]
}