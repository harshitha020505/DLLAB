{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUpPqPZYUitLja0xAdd00V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha020505/DLLAB/blob/main/DLlab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fewgwv07nPsG",
        "outputId": "3faf941a-3765-4de9-a2b5-3fe8cb77ba4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "#AND\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights=weights\n",
        "    self.bias=bias\n",
        "  def predict(self,inputs):\n",
        "    a=np.dot(self.weights,inputs)+self.bias\n",
        "    return step(a)\n",
        "weights=np.array([1,1])\n",
        "bias=-2\n",
        "perceptron=Perceptron(weights,bias)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OR\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights=weights\n",
        "    self.bias=bias\n",
        "  def predict(self,inputs):\n",
        "    a=np.dot(self.weights,inputs)+self.bias\n",
        "    return step(a)\n",
        "weights=np.array([1,1])\n",
        "bias=-1\n",
        "perceptron=Perceptron(weights,bias)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80ga8ZT0na04",
        "outputId": "aadcbc4e-f2f8-458c-ca9c-a4c69f8ef1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XOR and XNOR is not possible using single perceptron because the four points are not linearly seperable."
      ],
      "metadata": {
        "id": "KwcpiAhkUjWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XOR using MLP\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,weights3,bias1,bias2,bias3):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "    self.weights3=weights3\n",
        "    self.bias3=bias3\n",
        "  def predict(self,inputs):\n",
        "    a=step(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    b=step(np.dot(self.weights2,inputs)+self.bias2)\n",
        "    output=step(self.weights3[0]*a+self.weights3[1]*b+self.bias3)\n",
        "    return output\n",
        "weights1=np.array([1,1])\n",
        "bias1=-0.5\n",
        "weights2=np.array([1,1])\n",
        "bias2=-1.5\n",
        "weights3=np.array([1,-2])\n",
        "bias3=-0.5\n",
        "perceptron=Perceptron(weights1,weights2,weights3,bias1,bias2,bias3)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_DVqyOVtV6n",
        "outputId": "4a9ab7da-0d99-41e2-d16d-a0d7a2328bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XNOR using MLP\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,weights3,bias1,bias2,bias3):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "    self.weights3=weights3\n",
        "    self.bias3=bias3\n",
        "  def predict(self,inputs):\n",
        "    a=step(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    b=step(np.dot(self.weights2,inputs)+self.bias2)\n",
        "    output=step(self.weights3[0]*a+self.weights3[1]*b+self.bias3)\n",
        "    return output\n",
        "weights1=np.array([1,1])\n",
        "bias1=-0.5\n",
        "weights2=np.array([1,1])\n",
        "bias2=-1.5\n",
        "weights3=np.array([-1,2])\n",
        "bias3=0.5\n",
        "perceptron=Perceptron(weights1,weights2,weights3,bias1,bias2,bias3)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htnWE8O83K6d",
        "outputId": "4894d744-3dc3-4819-b1c6-ce19adcf2ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XOR Using NAND\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,weights3,bias1,bias2,bias3):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "    self.weights3=weights3\n",
        "    self.bias3=bias3\n",
        "  def predict(self,inputs):\n",
        "    a=step(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    # print(\"or\",a)\n",
        "    b=step(np.dot(self.weights2,inputs)+self.bias2)\n",
        "    # print(\"and\",b)\n",
        "    output=step(np.dot(self.weights3,np.array([a,b]))+self.bias3)\n",
        "    return output\n",
        "weights1=np.array([1,1])\n",
        "bias1=-0.5\n",
        "weights2=np.array([-1,-1])\n",
        "bias2=1.5\n",
        "weights3=np.array([1,1])\n",
        "bias3=-1.5\n",
        "perceptron=Perceptron(weights1,weights2,weights3,bias1,bias2,bias3)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2EjOs7by3Xj",
        "outputId": "b1e059a8-ae74-4f06-9967-4f77b027165b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Thresholding logic usedd by perceptron is very harsh\n",
        "import torch\n",
        "\n",
        "x1 = torch.tensor([0.0001])\n",
        "x2 = torch.tensor([-0.0001])\n",
        "\n",
        "y1 = (x1 >= 0).float()\n",
        "y2 = (x2 >= 0).float()\n",
        "\n",
        "print(\"Input 1:\", x1.item(), \"Output:\", y1.item())\n",
        "print(\"Input 2:\", x2.item(), \"Output:\", y2.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRDwKqTVVwjP",
        "outputId": "316e1db9-f248-42ef-9f49-03ac5990244f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 1: 9.999999747378752e-05 Output: 1.0\n",
            "Input 2: -9.999999747378752e-05 Output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "EC7doAWzBm43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Movie question\n",
        "def step(a):\n",
        "  return 1 if a>2 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights=weights\n",
        "    self.bias=bias\n",
        "  def predict(self,inputs):\n",
        "    a=np.dot(self.weights,inputs)+self.bias\n",
        "    return step(a)\n",
        "weights=np.array([1,1,1,1])\n",
        "inputs=[[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,1,0,0],[1,0,0,0],[0,0,1,1],[0,1,0,1],[1,0,0,1],[0,1,1,0],[1,0,1,0],[1,1,0,0],[1,1,1,0],[0,1,1,1],[1,0,1,1],[1,1,0,1],[1,1,1,1]]\n",
        "\n",
        "bias=-1\n",
        "perceptron=Perceptron(weights,bias)\n",
        "for i in range(16):\n",
        "  print(perceptron.predict(inputs[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKStei0X5Ugj",
        "outputId": "b4cc7d92-abcc-4317-8439-bd5756f15118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Perceptron Learning Algorithm â€“ Movie Preference Prediction\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Create and Save Dataset (CSV)\n",
        "# ------------------------------------------------------------\n",
        "data = {\n",
        "    'f1': [1, 1, 0, 0, 0, 1, 0, 1],   # Matt Damon\n",
        "    'f2': [1, 0, 1, 0, 0, 0, 1, 1],   # Thriller\n",
        "    'f3': [0, 0, 1, 1, 0, 1, 0, 1],   # Christopher Nolan\n",
        "    'f4': [0.85, 0.60, 0.90, 0.75, 0.40, 0.30, 0.45, 0.95],  # IMDb rating\n",
        "    'y' : [1, 1, 1, 1, 0, 0, 0, 1]    # Like (1) / Dislike (0)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"movies.csv\", index=False)\n",
        "\n",
        "print(\"Dataset created:\\n\")\n",
        "print(df)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Load Dataset\n",
        "# ------------------------------------------------------------\n",
        "data = pd.read_csv(\"movies.csv\")\n",
        "\n",
        "X = data[['f1', 'f2', 'f3', 'f4']].values\n",
        "y = data['y'].values\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3. Step Activation Function\n",
        "# ------------------------------------------------------------\n",
        "def step(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# i) MP Perceptron (No weights, No bias)\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"MP PERCEPTRON (No weights, No bias)\")\n",
        "print(\"==============================\")\n",
        "\n",
        "def mp_perceptron(x):\n",
        "    return step(np.sum(x))\n",
        "\n",
        "for i in range(len(X)):\n",
        "    pred = mp_perceptron(X[i])\n",
        "    print(f\"Input: {X[i]}  True: {y[i]}  Predicted: {pred}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# ii) Perceptron with Weights ONLY\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"PERCEPTRON WITH WEIGHTS ONLY\")\n",
        "print(\"==============================\")\n",
        "\n",
        "def train_perceptron_weights_only(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            z = np.dot(w, X[i])\n",
        "            y_pred = step(z)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            errors += abs(error)\n",
        "        print(f\"Epoch {epoch+1} | Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w\n",
        "\n",
        "w_no_bias = train_perceptron_weights_only(X, y)\n",
        "print(\"Final Weights (No Bias):\", w_no_bias)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# iii) Perceptron with Weights AND Bias\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"PERCEPTRON WITH WEIGHTS AND BIAS\")\n",
        "print(\"==============================\")\n",
        "\n",
        "def train_perceptron(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            z = np.dot(w, X[i]) + b\n",
        "            y_pred = step(z)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            b += lr * error\n",
        "            errors += abs(error)\n",
        "        print(f\"Epoch {epoch+1} | Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w, b\n",
        "\n",
        "w, b = train_perceptron(X, y)\n",
        "print(\"Final Weights:\", w)\n",
        "print(\"Final Bias:\", b)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4. Test with a Sample Movie\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"TESTING WITH A SAMPLE MOVIE\")\n",
        "print(\"==============================\")\n",
        "\n",
        "# Sample Movie:\n",
        "# Matt Damon = 1, Thriller = 1, Nolan = 0, IMDb = 0.80\n",
        "test_movie = np.array([1, 1, 0, 0.80])\n",
        "\n",
        "mp_result = mp_perceptron(test_movie)\n",
        "no_bias_result = step(np.dot(w_no_bias, test_movie))\n",
        "bias_result = step(np.dot(w, test_movie) + b)\n",
        "\n",
        "print(\"Test Movie Features:\", test_movie)\n",
        "print(\"MP Perceptron Prediction:\", mp_result)\n",
        "print(\"Perceptron (Weights Only) Prediction:\", no_bias_result)\n",
        "print(\"Perceptron (Weights + Bias) Prediction:\", bias_result)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5. Conclusion\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"OBSERVATIONS\")\n",
        "print(\"==============================\")\n",
        "print(\"MP Perceptron: No learning, poor classification\")\n",
        "print(\"Weights Only: Learns slowly, limited decision boundary\")\n",
        "print(\"Weights + Bias: Fast convergence and accurate prediction\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YbLkoF8WIu7",
        "outputId": "78161ae6-05bb-4995-86dd-07f2bf243cee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created:\n",
            "\n",
            "   f1  f2  f3    f4  y\n",
            "0   1   1   0  0.85  1\n",
            "1   1   0   0  0.60  1\n",
            "2   0   1   1  0.90  1\n",
            "3   0   0   1  0.75  1\n",
            "4   0   0   0  0.40  0\n",
            "5   1   0   1  0.30  0\n",
            "6   0   1   0  0.45  0\n",
            "7   1   1   1  0.95  1\n",
            "\n",
            "==============================\n",
            "MP PERCEPTRON (No weights, No bias)\n",
            "==============================\n",
            "Input: [1.   1.   0.   0.85]  True: 1  Predicted: 1\n",
            "Input: [1.  0.  0.  0.6]  True: 1  Predicted: 1\n",
            "Input: [0.  1.  1.  0.9]  True: 1  Predicted: 1\n",
            "Input: [0.   0.   1.   0.75]  True: 1  Predicted: 1\n",
            "Input: [0.  0.  0.  0.4]  True: 0  Predicted: 1\n",
            "Input: [1.  0.  1.  0.3]  True: 0  Predicted: 1\n",
            "Input: [0.   1.   0.   0.45]  True: 0  Predicted: 1\n",
            "Input: [1.   1.   1.   0.95]  True: 1  Predicted: 1\n",
            "\n",
            "==============================\n",
            "PERCEPTRON WITH WEIGHTS ONLY\n",
            "==============================\n",
            "Epoch 1 | Errors: 2\n",
            "Epoch 2 | Errors: 4\n",
            "Epoch 3 | Errors: 4\n",
            "Epoch 4 | Errors: 4\n",
            "Epoch 5 | Errors: 3\n",
            "Epoch 6 | Errors: 4\n",
            "Epoch 7 | Errors: 3\n",
            "Epoch 8 | Errors: 4\n",
            "Epoch 9 | Errors: 3\n",
            "Epoch 10 | Errors: 4\n",
            "Epoch 11 | Errors: 3\n",
            "Epoch 12 | Errors: 4\n",
            "Epoch 13 | Errors: 3\n",
            "Epoch 14 | Errors: 4\n",
            "Epoch 15 | Errors: 3\n",
            "Epoch 16 | Errors: 4\n",
            "Epoch 17 | Errors: 3\n",
            "Epoch 18 | Errors: 4\n",
            "Epoch 19 | Errors: 3\n",
            "Epoch 20 | Errors: 4\n",
            "Final Weights (No Bias): [ 0.1    0.1    0.1   -0.005]\n",
            "\n",
            "==============================\n",
            "PERCEPTRON WITH WEIGHTS AND BIAS\n",
            "==============================\n",
            "Epoch 1 | Errors: 2\n",
            "Epoch 2 | Errors: 3\n",
            "Epoch 3 | Errors: 3\n",
            "Epoch 4 | Errors: 4\n",
            "Epoch 5 | Errors: 1\n",
            "Epoch 6 | Errors: 4\n",
            "Epoch 7 | Errors: 4\n",
            "Epoch 8 | Errors: 3\n",
            "Epoch 9 | Errors: 3\n",
            "Epoch 10 | Errors: 0\n",
            "Final Weights: [0.1 0.1 0.  0.4]\n",
            "Final Bias: -0.30000000000000004\n",
            "\n",
            "==============================\n",
            "TESTING WITH A SAMPLE MOVIE\n",
            "==============================\n",
            "Test Movie Features: [1.  1.  0.  0.8]\n",
            "MP Perceptron Prediction: 1\n",
            "Perceptron (Weights Only) Prediction: 1\n",
            "Perceptron (Weights + Bias) Prediction: 1\n",
            "\n",
            "==============================\n",
            "OBSERVATIONS\n",
            "==============================\n",
            "MP Perceptron: No learning, poor classification\n",
            "Weights Only: Learns slowly, limited decision boundary\n",
            "Weights + Bias: Fast convergence and accurate prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "def step(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "\n",
        "def train_perceptron(X, y, lr=0.1, epochs=50):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "    for _ in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            y_pred = step(np.dot(w, X[i]) + b)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            b += lr * error\n",
        "            errors += abs(error)\n",
        "        if errors == 0:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "boolean_functions = list(product([0, 1], repeat=4))\n",
        "\n",
        "linearly_separable = 0\n",
        "not_separable = 0\n",
        "failed_functions = []\n",
        "\n",
        "for func in boolean_functions:\n",
        "    y = np.array(func)\n",
        "    converged = train_perceptron(X, y)\n",
        "    if converged:\n",
        "        linearly_separable += 1\n",
        "    else:\n",
        "        not_separable += 1\n",
        "        failed_functions.append(func)\n",
        "\n",
        "print(\"Total Boolean functions (n=2):\", len(boolean_functions))\n",
        "print(\"Linearly separable:\", linearly_separable)\n",
        "print(\"Not linearly separable:\", not_separable)\n",
        "\n",
        "print(\"\\nNon-linearly separable functions (truth tables):\")\n",
        "for f in failed_functions:\n",
        "    print(f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJZzkITLWiv0",
        "outputId": "1b9296c0-d76b-4ea8-d8d7-ae2674463809"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Boolean functions (n=2): 16\n",
            "Linearly separable: 14\n",
            "Not linearly separable: 2\n",
            "\n",
            "Non-linearly separable functions (truth tables):\n",
            "(0, 1, 1, 0)\n",
            "(1, 0, 0, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def step(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "def hidden_layer(x1, x2):\n",
        "    h1 = step(-x1 - x2 + 1.5)   # fires for (0,0)\n",
        "    h2 = step(-x1 + x2 - 0.5)   # fires for (0,1)\n",
        "    h3 = step(x1 - x2 - 0.5)    # fires for (1,0)\n",
        "    h4 = step(x1 + x2 - 1.5)    # fires for (1,1)\n",
        "\n",
        "    return np.array([h1, h2, h3, h4])\n",
        "def mlp(x1, x2, w):\n",
        "    h = hidden_layer(x1, x2)\n",
        "    return step(np.dot(w, h) - 0.5)\n",
        "inputs = [(0,0), (0,1), (1,0), (1,1)]\n",
        "functions = {\n",
        "    \"AND\":   [0, 0, 0, 1],\n",
        "    \"OR\":    [0, 1, 1, 1],\n",
        "    \"XOR\":   [0, 1, 1, 0],\n",
        "    \"XNOR\":  [0, -1, -1, 0],\n",
        "    \"NAND\":  [1, 1, 1, 0],\n",
        "    \"NOR\":   [1, 0, 0, 0]\n",
        "}\n",
        "for name, weights in functions.items():\n",
        "    print(f\"\\n{name} function:\")\n",
        "    for x1, x2 in inputs:\n",
        "        print(f\"{x1} {x2} -> {mlp(x1, x2, np.array(weights))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSjZgfNGB7P8",
        "outputId": "4b5e19db-a67c-4781-abad-2376f75a9af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AND function:\n",
            "0 0 -> 0\n",
            "0 1 -> 0\n",
            "1 0 -> 0\n",
            "1 1 -> 1\n",
            "\n",
            "OR function:\n",
            "0 0 -> 0\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 1\n",
            "\n",
            "XOR function:\n",
            "0 0 -> 0\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 0\n",
            "\n",
            "XNOR function:\n",
            "0 0 -> 0\n",
            "0 1 -> 0\n",
            "1 0 -> 0\n",
            "1 1 -> 0\n",
            "\n",
            "NAND function:\n",
            "0 0 -> 1\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 0\n",
            "\n",
            "NOR function:\n",
            "0 0 -> 1\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "# Demonstrate the Representation Power of a Network of Perceptrons\n",
        "# a) How many Boolean functions can be designed using two binary inputs?\n",
        "# b) For each Boolean function, determine whether it is linearly separable.\n",
        "# c) mplement a single perceptron model and test whether it can correctly learn each Boolean function. (Mention how many it can't learn and why)\n",
        "# d) Extend the program to estimate or analyze how the number of non-linearly separable Boolean functions increases as the number of inputs n grows.\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "# -----------------------------\n",
        "# Binary input combinations (2 inputs)\n",
        "# -----------------------------\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "# Step activation\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# -----------------------------\n",
        "# Single Perceptron Training\n",
        "# -----------------------------\n",
        "def train_perceptron(X, y, lr=0.1, epochs=50):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            y_pred = step(np.dot(X[i], w) + b)\n",
        "            error = y[i] - y_pred\n",
        "            if error != 0:\n",
        "                w += lr * error * X[i]\n",
        "                b += lr * error\n",
        "                errors += 1\n",
        "        if errors == 0:\n",
        "            return True   # Converged (linearly separable)\n",
        "    return False          # Not converged (not linearly separable)\n",
        "\n",
        "# -----------------------------\n",
        "# (a) Total Boolean Functions\n",
        "# -----------------------------\n",
        "n = 2\n",
        "total_functions = 2 ** (2 ** n)\n",
        "print(\"Total Boolean functions (n=2):\", total_functions)\n",
        "\n",
        "# -----------------------------\n",
        "# (b) Generate all Boolean functions\n",
        "# -----------------------------\n",
        "boolean_functions = list(itertools.product([0, 1], repeat=4))\n",
        "\n",
        "linearly_separable = 0\n",
        "not_separable = 0\n",
        "\n",
        "print(\"\\nTesting Boolean Functions:\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# (c) Test each Boolean function\n",
        "# -----------------------------\n",
        "for idx, func in enumerate(boolean_functions):\n",
        "    y = np.array(func)\n",
        "    learned = train_perceptron(X, y)\n",
        "\n",
        "    if learned:\n",
        "        linearly_separable += 1\n",
        "        result = \"Linearly Separable\"\n",
        "    else:\n",
        "        not_separable += 1\n",
        "        result = \"Not Linearly Separable\"\n",
        "\n",
        "    print(f\"Function {idx+1}: {func} --> {result}\")\n",
        "\n",
        "print(\"\\nSummary for n = 2\")\n",
        "print(\"Linearly separable functions:\", linearly_separable)\n",
        "\n",
        "print(\"Not linearly separable functions:\", not_separable)\n",
        "\n",
        "# -----------------------------\n",
        "# (d) Growth of Non-linearly Separable Functions\n",
        "# -----------------------------\n",
        "print(\"\\nGrowth Analysis:\")\n",
        "for n in range(1, 6):\n",
        "    total = 2 ** (2 ** n)\n",
        "    print(f\"Inputs = {n} | Total Boolean Functions = {total}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAXRd_7BHgOZ",
        "outputId": "cf13b19f-7a18-4f9f-fe39-0db4cc89dd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Boolean functions (n=2): 16\n",
            "\n",
            "Testing Boolean Functions:\n",
            "\n",
            "Function 1: (0, 0, 0, 0) --> Linearly Separable\n",
            "Function 2: (0, 0, 0, 1) --> Linearly Separable\n",
            "Function 3: (0, 0, 1, 0) --> Linearly Separable\n",
            "Function 4: (0, 0, 1, 1) --> Linearly Separable\n",
            "Function 5: (0, 1, 0, 0) --> Linearly Separable\n",
            "Function 6: (0, 1, 0, 1) --> Linearly Separable\n",
            "Function 7: (0, 1, 1, 0) --> Not Linearly Separable\n",
            "Function 8: (0, 1, 1, 1) --> Linearly Separable\n",
            "Function 9: (1, 0, 0, 0) --> Linearly Separable\n",
            "Function 10: (1, 0, 0, 1) --> Not Linearly Separable\n",
            "Function 11: (1, 0, 1, 0) --> Linearly Separable\n",
            "Function 12: (1, 0, 1, 1) --> Linearly Separable\n",
            "Function 13: (1, 1, 0, 0) --> Linearly Separable\n",
            "Function 14: (1, 1, 0, 1) --> Linearly Separable\n",
            "Function 15: (1, 1, 1, 0) --> Linearly Separable\n",
            "Function 16: (1, 1, 1, 1) --> Linearly Separable\n",
            "\n",
            "Summary for n = 2\n",
            "Linearly separable functions: 14\n",
            "Not linearly separable functions: 2\n",
            "\n",
            "Growth Analysis:\n",
            "Inputs = 1 | Total Boolean Functions = 4\n",
            "Inputs = 2 | Total Boolean Functions = 16\n",
            "Inputs = 3 | Total Boolean Functions = 256\n",
            "Inputs = 4 | Total Boolean Functions = 65536\n",
            "Inputs = 5 | Total Boolean Functions = 4294967296\n"
          ]
        }
      ]
    }
  ]
}