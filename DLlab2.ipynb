{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLZEBbCATOb/4V7gSHWfRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha020505/DLLAB/blob/main/DLlab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fewgwv07nPsG",
        "outputId": "3faf941a-3765-4de9-a2b5-3fe8cb77ba4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "#AND\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights=weights\n",
        "    self.bias=bias\n",
        "  def predict(self,inputs):\n",
        "    a=np.dot(self.weights,inputs)+self.bias\n",
        "    return step(a)\n",
        "weights=np.array([1,1])\n",
        "bias=-2\n",
        "perceptron=Perceptron(weights,bias)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OR\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights=weights\n",
        "    self.bias=bias\n",
        "  def predict(self,inputs):\n",
        "    a=np.dot(self.weights,inputs)+self.bias\n",
        "    return step(a)\n",
        "weights=np.array([1,1])\n",
        "bias=-1\n",
        "perceptron=Perceptron(weights,bias)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80ga8ZT0na04",
        "outputId": "aadcbc4e-f2f8-458c-ca9c-a4c69f8ef1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def sigmoid(a):\n",
        "  return 1/(1+np.exp(-a))\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,bias1,bias2):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "  def predict(self,inputs):\n",
        "    a=sigmoid(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    print(a)\n",
        "    output=sigmoid(np.dot(self.weights2,a)+self.bias2)\n",
        "    print(output)\n",
        "    return 1 if output>=0.5 else 0\n",
        "weights1=np.array([[1,1],[1,1]])\n",
        "bias1=np.array([-0.5,-1.5])\n",
        "weights2=np.array([1,-2])\n",
        "bias2=-0.5\n",
        "perceptron=Perceptron(weights1,weights2,bias1,bias2)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbVx_nLtpuFd",
        "outputId": "573cc3a0-5979-49b5-b444-e75c087d8df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.37754067 0.18242552]\n",
            "0.38052737803921666\n",
            "1\n",
            "[0.62245933 0.37754067]\n",
            "0.3469162437740144\n",
            "1\n",
            "[0.62245933 0.37754067]\n",
            "0.3469162437740144\n",
            "1\n",
            "[0.81757448 0.62245933]\n",
            "0.283463832038694\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XOR using MLP\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,weights3,bias1,bias2,bias3):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "    self.weights3=weights3\n",
        "    self.bias3=bias3\n",
        "  def predict(self,inputs):\n",
        "    a=step(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    b=step(np.dot(self.weights2,inputs)+self.bias2)\n",
        "    output=step(self.weights3[0]*a+self.weights3[1]*b+self.bias3)\n",
        "    return output\n",
        "weights1=np.array([1,1])\n",
        "bias1=-0.5\n",
        "weights2=np.array([1,1])\n",
        "bias2=-1.5\n",
        "weights3=np.array([1,-2])\n",
        "bias3=-0.5\n",
        "perceptron=Perceptron(weights1,weights2,weights3,bias1,bias2,bias3)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_DVqyOVtV6n",
        "outputId": "4a9ab7da-0d99-41e2-d16d-a0d7a2328bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XNOR using MLP\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,weights3,bias1,bias2,bias3):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "    self.weights3=weights3\n",
        "    self.bias3=bias3\n",
        "  def predict(self,inputs):\n",
        "    a=step(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    b=step(np.dot(self.weights2,inputs)+self.bias2)\n",
        "    output=step(self.weights3[0]*a+self.weights3[1]*b+self.bias3)\n",
        "    return output\n",
        "weights1=np.array([1,1])\n",
        "bias1=-0.5\n",
        "weights2=np.array([1,1])\n",
        "bias2=-1.5\n",
        "weights3=np.array([-1,2])\n",
        "bias3=0.5\n",
        "perceptron=Perceptron(weights1,weights2,weights3,bias1,bias2,bias3)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htnWE8O83K6d",
        "outputId": "4894d744-3dc3-4819-b1c6-ce19adcf2ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XOR Using NAND\n",
        "import numpy as np\n",
        "def step(a):\n",
        "  return 1 if a>=0 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights1,weights2,weights3,bias1,bias2,bias3):\n",
        "    self.weights1=weights1\n",
        "    self.bias1=bias1\n",
        "    self.weights2=weights2\n",
        "    self.bias2=bias2\n",
        "    self.weights3=weights3\n",
        "    self.bias3=bias3\n",
        "  def predict(self,inputs):\n",
        "    a=step(np.dot(self.weights1,inputs)+self.bias1)\n",
        "    # print(\"or\",a)\n",
        "    b=step(np.dot(self.weights2,inputs)+self.bias2)\n",
        "    # print(\"and\",b)\n",
        "    output=step(np.dot(self.weights3,np.array([a,b]))+self.bias3)\n",
        "    return output\n",
        "weights1=np.array([1,1])\n",
        "bias1=-0.5\n",
        "weights2=np.array([-1,-1])\n",
        "bias2=1.5\n",
        "weights3=np.array([1,1])\n",
        "bias3=-1.5\n",
        "perceptron=Perceptron(weights1,weights2,weights3,bias1,bias2,bias3)\n",
        "inputs=[[0,0],[0,1],[1,0],[1,1]]\n",
        "for i in inputs:\n",
        "  print(perceptron.predict(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2EjOs7by3Xj",
        "outputId": "b1e059a8-ae74-4f06-9967-4f77b027165b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "EC7doAWzBm43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Movie question\n",
        "def step(a):\n",
        "  return 1 if a>2 else 0\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights=weights\n",
        "    self.bias=bias\n",
        "  def predict(self,inputs):\n",
        "    a=np.dot(self.weights,inputs)+self.bias\n",
        "    return step(a)\n",
        "weights=np.array([1,1,1,1])\n",
        "inputs=[[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,1,0,0],[1,0,0,0],[0,0,1,1],[0,1,0,1],[1,0,0,1],[0,1,1,0],[1,0,1,0],[1,1,0,0],[1,1,1,0],[0,1,1,1],[1,0,1,1],[1,1,0,1],[1,1,1,1]]\n",
        "\n",
        "bias=-1\n",
        "perceptron=Perceptron(weights,bias)\n",
        "for i in range(16):\n",
        "  print(perceptron.predict(inputs[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKStei0X5Ugj",
        "outputId": "b4cc7d92-abcc-4317-8439-bd5756f15118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def step(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "def hidden_layer(x1, x2):\n",
        "    h1 = step(-x1 - x2 + 1.5)   # fires for (0,0)\n",
        "    h2 = step(-x1 + x2 - 0.5)   # fires for (0,1)\n",
        "    h3 = step(x1 - x2 - 0.5)    # fires for (1,0)\n",
        "    h4 = step(x1 + x2 - 1.5)    # fires for (1,1)\n",
        "\n",
        "    return np.array([h1, h2, h3, h4])\n",
        "def mlp(x1, x2, w):\n",
        "    h = hidden_layer(x1, x2)\n",
        "    return step(np.dot(w, h) - 0.5)\n",
        "inputs = [(0,0), (0,1), (1,0), (1,1)]\n",
        "functions = {\n",
        "    \"AND\":   [0, 0, 0, 1],\n",
        "    \"OR\":    [0, 1, 1, 1],\n",
        "    \"XOR\":   [0, 1, 1, 0],\n",
        "    \"XNOR\":  [0, -1, -1, 0],\n",
        "    \"NAND\":  [1, 1, 1, 0],\n",
        "    \"NOR\":   [1, 0, 0, 0]\n",
        "}\n",
        "for name, weights in functions.items():\n",
        "    print(f\"\\n{name} function:\")\n",
        "    for x1, x2 in inputs:\n",
        "        print(f\"{x1} {x2} -> {mlp(x1, x2, np.array(weights))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSjZgfNGB7P8",
        "outputId": "4b5e19db-a67c-4781-abad-2376f75a9af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AND function:\n",
            "0 0 -> 0\n",
            "0 1 -> 0\n",
            "1 0 -> 0\n",
            "1 1 -> 1\n",
            "\n",
            "OR function:\n",
            "0 0 -> 0\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 1\n",
            "\n",
            "XOR function:\n",
            "0 0 -> 0\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 0\n",
            "\n",
            "XNOR function:\n",
            "0 0 -> 0\n",
            "0 1 -> 0\n",
            "1 0 -> 0\n",
            "1 1 -> 0\n",
            "\n",
            "NAND function:\n",
            "0 0 -> 1\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 0\n",
            "\n",
            "NOR function:\n",
            "0 0 -> 1\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "# Demonstrate the Representation Power of a Network of Perceptrons\n",
        "# a) How many Boolean functions can be designed using two binary inputs?\n",
        "# b) For each Boolean function, determine whether it is linearly separable.\n",
        "# c) mplement a single perceptron model and test whether it can correctly learn each Boolean function. (Mention how many it can't learn and why)\n",
        "# d) Extend the program to estimate or analyze how the number of non-linearly separable Boolean functions increases as the number of inputs n grows.\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "# -----------------------------\n",
        "# Binary input combinations (2 inputs)\n",
        "# -----------------------------\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "# Step activation\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# -----------------------------\n",
        "# Single Perceptron Training\n",
        "# -----------------------------\n",
        "def train_perceptron(X, y, lr=0.1, epochs=50):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            y_pred = step(np.dot(X[i], w) + b)\n",
        "            error = y[i] - y_pred\n",
        "            if error != 0:\n",
        "                w += lr * error * X[i]\n",
        "                b += lr * error\n",
        "                errors += 1\n",
        "        if errors == 0:\n",
        "            return True   # Converged (linearly separable)\n",
        "    return False          # Not converged (not linearly separable)\n",
        "\n",
        "# -----------------------------\n",
        "# (a) Total Boolean Functions\n",
        "# -----------------------------\n",
        "n = 2\n",
        "total_functions = 2 ** (2 ** n)\n",
        "print(\"Total Boolean functions (n=2):\", total_functions)\n",
        "\n",
        "# -----------------------------\n",
        "# (b) Generate all Boolean functions\n",
        "# -----------------------------\n",
        "boolean_functions = list(itertools.product([0, 1], repeat=4))\n",
        "\n",
        "linearly_separable = 0\n",
        "not_separable = 0\n",
        "\n",
        "print(\"\\nTesting Boolean Functions:\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# (c) Test each Boolean function\n",
        "# -----------------------------\n",
        "for idx, func in enumerate(boolean_functions):\n",
        "    y = np.array(func)\n",
        "    learned = train_perceptron(X, y)\n",
        "\n",
        "    if learned:\n",
        "        linearly_separable += 1\n",
        "        result = \"Linearly Separable\"\n",
        "    else:\n",
        "        not_separable += 1\n",
        "        result = \"Not Linearly Separable\"\n",
        "\n",
        "    print(f\"Function {idx+1}: {func} --> {result}\")\n",
        "\n",
        "print(\"\\nSummary for n = 2\")\n",
        "print(\"Linearly separable functions:\", linearly_separable)\n",
        "\n",
        "print(\"Not linearly separable functions:\", not_separable)\n",
        "\n",
        "# -----------------------------\n",
        "# (d) Growth of Non-linearly Separable Functions\n",
        "# -----------------------------\n",
        "print(\"\\nGrowth Analysis:\")\n",
        "for n in range(1, 6):\n",
        "    total = 2 ** (2 ** n)\n",
        "    print(f\"Inputs = {n} | Total Boolean Functions = {total}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAXRd_7BHgOZ",
        "outputId": "cf13b19f-7a18-4f9f-fe39-0db4cc89dd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Boolean functions (n=2): 16\n",
            "\n",
            "Testing Boolean Functions:\n",
            "\n",
            "Function 1: (0, 0, 0, 0) --> Linearly Separable\n",
            "Function 2: (0, 0, 0, 1) --> Linearly Separable\n",
            "Function 3: (0, 0, 1, 0) --> Linearly Separable\n",
            "Function 4: (0, 0, 1, 1) --> Linearly Separable\n",
            "Function 5: (0, 1, 0, 0) --> Linearly Separable\n",
            "Function 6: (0, 1, 0, 1) --> Linearly Separable\n",
            "Function 7: (0, 1, 1, 0) --> Not Linearly Separable\n",
            "Function 8: (0, 1, 1, 1) --> Linearly Separable\n",
            "Function 9: (1, 0, 0, 0) --> Linearly Separable\n",
            "Function 10: (1, 0, 0, 1) --> Not Linearly Separable\n",
            "Function 11: (1, 0, 1, 0) --> Linearly Separable\n",
            "Function 12: (1, 0, 1, 1) --> Linearly Separable\n",
            "Function 13: (1, 1, 0, 0) --> Linearly Separable\n",
            "Function 14: (1, 1, 0, 1) --> Linearly Separable\n",
            "Function 15: (1, 1, 1, 0) --> Linearly Separable\n",
            "Function 16: (1, 1, 1, 1) --> Linearly Separable\n",
            "\n",
            "Summary for n = 2\n",
            "Linearly separable functions: 14\n",
            "Not linearly separable functions: 2\n",
            "\n",
            "Growth Analysis:\n",
            "Inputs = 1 | Total Boolean Functions = 4\n",
            "Inputs = 2 | Total Boolean Functions = 16\n",
            "Inputs = 3 | Total Boolean Functions = 256\n",
            "Inputs = 4 | Total Boolean Functions = 65536\n",
            "Inputs = 5 | Total Boolean Functions = 4294967296\n"
          ]
        }
      ]
    }
  ]
}